{
  "episode_id": "aishwarya-naresh-reganti-kiriti-badam",
  "quotes": [
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t1_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t1",
      "topic_title": "Introduction and Background",
      "text": "Most people tend to ignore the non-determinism. You don't know how the user might behave with your product, and you also don't know how the LLM might respond to that. The second difference is the agency control trade-off. Every time you hand over decision-making capabilities to agentic systems, you're kind of relinquishing some amount of control on your end.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:00:08",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=8s",
      "context": "Highlights two core AI-product differences\u2014non-determinism and the agency/control trade-off\u2014that should shape product design and risk management.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t1_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t1",
      "topic_title": "Introduction and Background",
      "text": "So we recommend building step-by-step. When you start small, it forces you to think about what is the problem that I'm going to solve. In all this advancements of the AI, one easy, slippery slope is to keep thinking about complexities of the solution and forget the problem that you're trying to solve.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:00:28",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=28s",
      "context": "A practical methodology: iterate from small, problem-first steps to avoid getting lost in AI solution complexity.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t1_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t1",
      "topic_title": "Introduction and Background",
      "text": "It's not about being the first company to have an agent among your competitors. It's about have you built the right flywheels in place so that you can improve over time.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:00:42",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=42s",
      "context": "Reframes competitive advantage from shipping \u201cagents\u201d first to building improvement loops that compound over time.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t1_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t1",
      "topic_title": "Introduction and Background",
      "text": "Persistence is extremely valuable. Successful companies right now building in any new area, they are going through the pain of learning this, implementing this and understanding what works and what doesn't work. Pain is the new moat.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:01:16",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=76s",
      "context": "A counterintuitive moat: enduring the learning/implementation pain that others won\u2019t, especially in new AI domains.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t2_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t2",
      "topic_title": "Sponsor Break",
      "text": "Product leaders hate building integrations. They're messy. They're slow to build. They're a huge drain on your roadmap, and they're definitely not why you got into product in the first place.",
      "speaker": "Lenny",
      "timestamp": "00:02:49",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=169s",
      "context": "Captures a common product pain point and frames integrations as a roadmap tax worth minimizing or outsourcing.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t2_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t2",
      "topic_title": "Sponsor Break",
      "text": "With a single API, B2B SaaS companies embed Merge into their product and ship 220 plus customer-facing integrations in weeks, not quarters.",
      "speaker": "Lenny",
      "timestamp": "00:02:49",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=169s",
      "context": "Provides a concrete scaling approach (single API) plus a specific benchmark for integration velocity and scope.",
      "insight_type": "data"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t2_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t2",
      "topic_title": "Sponsor Break",
      "text": "Think of merge like Plaid, but for everything B2B SaaS.",
      "speaker": "Lenny",
      "timestamp": "00:03:14",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=194s",
      "context": "Offers a memorable analogy that helps practitioners quickly understand the product category and value proposition.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t2_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t2",
      "topic_title": "Sponsor Break",
      "text": "By the time the results are in, the moment to act has passed.",
      "speaker": "Lenny",
      "timestamp": "00:04:14",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=254s",
      "context": "Highlights the core failure mode of slow user research and why speed-to-insight is strategically important.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t2_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t2",
      "topic_title": "Sponsor Break",
      "text": "Strella's AI moderator asks real follow-up questions, probing deeper when answers are vague, and services patterns across hundreds of conversations all in a few hours, not weeks.",
      "speaker": "Lenny",
      "timestamp": "00:04:14",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=254s",
      "context": "Describes an actionable methodology shift\u2014automating interviews and synthesis\u2014to compress research cycles dramatically.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t3_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t3",
      "topic_title": "What\u2019s working and failing in AI adoption",
      "text": "And this year, a ton of companies are really rethinking their user experiences and their workflows and all of that and really understanding that you need to deconstruct and reconstruct your processes in order to build successful AI products.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:05:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=354s",
      "context": "Highlights a practical shift from bolting AI onto existing systems to redesigning workflows end-to-end for AI success.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t3_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t3",
      "topic_title": "What\u2019s working and failing in AI adoption",
      "text": "And the AI lifecycle, both pre-deployment and post-deployment is very different as compared to a traditional software lifecycle.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:05:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=354s",
      "context": "A key mental model: teams must plan for a fundamentally different build-and-iterate lifecycle than standard software.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t3_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t3",
      "topic_title": "What\u2019s working and failing in AI adoption",
      "text": "And so a lot of old contracts and handoffs between traditional roles, like say PMs and engineers and data folks has now been broken and people are really getting adapted to this new way of working together and kind of owning the same feedback loop in a way.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:06:57",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=417s",
      "context": "Actionable org design insight: traditional role boundaries and handoffs fail in AI, requiring shared ownership of iteration loops.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t3_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t3",
      "topic_title": "What\u2019s working and failing in AI adoption",
      "text": "Because previously, I feel like PMs and engineers and all of these folks had their own feedback loops to optimize. And now you need to be probably sitting in the same room. You're probably looking at agent traces together and deciding how your product should behave.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:06:57",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=417s",
      "context": "Concrete operating model: cross-functional teams should review agent traces together to align behavior and iterate faster.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t4_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t4",
      "topic_title": "Two core differences: nondeterminism and agency-control",
      "text": "You're pretty much working with a non-deterministic API as compared to traditional software.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:08:01",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=481s",
      "context": "A crisp mental model that reframes LLM-based product building as integrating an inherently variable API, which changes how you design, test, and ship.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t4_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t4",
      "topic_title": "Two core differences: nondeterminism and agency-control",
      "text": "But now that layer in AI products has completely been replaced by a very fluid interface, which is mostly natural language, which means the user can literally come up with a ton of ways of saying or communicating their intentions.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:08:59",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=539s",
      "context": "Highlights the practical implication that input variability explodes in AI UX, requiring teams to plan for many user phrasings rather than fixed flows.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t4_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t4",
      "topic_title": "Two core differences: nondeterminism and agency-control",
      "text": "So you don't know how the user might behave with your product, and you also don't know how the LLM might respond to that.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:08:59",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=539s",
      "context": "Captures the compounding uncertainty on both sides of the interaction, motivating more robust evaluation and guardrails than traditional software.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t4_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t4",
      "topic_title": "Two core differences: nondeterminism and agency-control",
      "text": "But every time you hand over decision-making capabilities or autonomy to agentic systems, you're kind of relinquishing some amount of control on your end.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:09:53",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=593s",
      "context": "A memorable articulation of the agency-control trade-off that helps practitioners reason about when (and how much) autonomy to grant.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t4_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t4",
      "topic_title": "Two core differences: nondeterminism and agency-control",
      "text": "And that's where we talk about this agency controlled trade-off, which is if you give your AI agent or your AI system, whatever it is, more agency, which is the ability to make decisions, you're also losing some control and you want to make sure that the agent or the AI system has earned that ability or has built up trust over time.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:09:53",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=593s",
      "context": "Actionable guidance to gate autonomy behind demonstrated reliability, framing trust as something the system must earn progressively.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t5_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t5",
      "topic_title": "Build step-by-step: start small, then increase autonomy",
      "text": "You don't start hiking it every day, but you start training yourself in minor parts and then you slowly improve and then you go to the end goal.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:11:39",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=699s",
      "context": "Uses a training-for-Half-Dome analogy as a step-by-step mental model for building toward more capable AI systems.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t5_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t5",
      "topic_title": "Build step-by-step: start small, then increase autonomy",
      "text": "I feel like that's extremely similar to what you want to build AI products in the sense that when you don't start with agents with all the tools and all the context that you have in the company in day one and expect it to work or even tinker at that level.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:11:39",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=699s",
      "context": "Warns against the common mistake of starting with fully tooled, fully contextualized agents on day one.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t5_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t5",
      "topic_title": "Build step-by-step: start small, then increase autonomy",
      "text": "You need to be deliberately starting in places where there is minimal impact and more human control so that you have a good grip of what are the current capabilities and what can I do with them and then slowly lean into the more agency and lesser control.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:11:39",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=699s",
      "context": "Gives a concrete build strategy: begin in low-risk areas with high human oversight, then increase autonomy over time.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t5_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t5",
      "topic_title": "Build step-by-step: start small, then increase autonomy",
      "text": "So this gives you that confidence that, okay, I can know that, okay, this is the particular problem that I'm facing and the AI can solve this extent of it.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:12:29",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=749s",
      "context": "Highlights an iterative validation loop: clarify the problem and empirically learn the boundary of what the AI can reliably handle.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t5_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t5",
      "topic_title": "Build step-by-step: start small, then increase autonomy",
      "text": "Everyone is starting from very minimalistic structures and then evolving.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:12:29",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=749s",
      "context": "Reframes the perceived gap between \u201cfancy agents\u201d and reality, encouraging teams to start simple rather than feel behind.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t6_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t6",
      "topic_title": "Customer support agent autonomy ladder example",
      "text": "So if you start with all of this on day one, it's incredibly hard to control the complexity.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:15:19",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=919s",
      "context": "A clear warning against launching fully autonomous agents immediately, emphasizing complexity control as the core reason to ladder autonomy.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t6_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t6",
      "topic_title": "Customer support agent autonomy ladder example",
      "text": "So we recommend building step by step and then increasing it.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:15:19",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=919s",
      "context": "A concise methodology for rolling out agent autonomy incrementally rather than all at once.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t6_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t6",
      "topic_title": "Customer support agent autonomy ladder example",
      "text": "I think the higher level idea here is with AI systems, it's all about behavior calibration. It's incredibly impossible to predict upfront how your system behaves.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:16:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=962s",
      "context": "A memorable mental model: treat AI development as calibrating behavior over time because upfront prediction is unreliable.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t6_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t6",
      "topic_title": "Customer support agent autonomy ladder example",
      "text": "And then you get that feedback loop from the humans that, okay, this is actually a good suggestion for me in this particular case and this is a bad suggestion.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:14:33",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=873s",
      "context": "Highlights a practical mechanism\u2014human-in-the-loop feedback\u2014to systematically improve agent quality before increasing autonomy.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t6_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t6",
      "topic_title": "Customer support agent autonomy ladder example",
      "text": "You can decide how to constrain that autonomy. I mean, a different example of how you could constrain autonomy is pre-authorization use cases.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:16:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=962s",
      "context": "Introduces a transferable approach: constrain autonomy by use-case risk (e.g., pre-authorization) rather than treating autonomy as all-or-nothing.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t7_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t7",
      "topic_title": "Behavior calibration, risk tiers, and flywheels",
      "text": "I think the higher level idea here is with AI systems, it's all about behavior calibration.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:16:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=962s",
      "context": "Introduces a memorable framing for building AI products: treat development as calibrating system behavior rather than expecting deterministic correctness upfront.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t7_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t7",
      "topic_title": "Behavior calibration, risk tiers, and flywheels",
      "text": "It's incredibly impossible to predict upfront how your system behaves.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:16:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=962s",
      "context": "Highlights the core non-determinism challenge that drives the need for staged rollout, constraints, and monitoring.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t7_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t7",
      "topic_title": "Behavior calibration, risk tiers, and flywheels",
      "text": "So you can kind of determine which of these use cases should go through that human and the loop layer versus which of the use cases AI can conveniently handle.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:17:11",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1031s",
      "context": "Gives an actionable risk-tiering approach: route higher-risk cases to humans while letting AI handle low-risk work.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t7_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t7",
      "topic_title": "Behavior calibration, risk tiers, and flywheels",
      "text": "And then all through this process, you're also logging what the human is doing because you want to build a flywheel that you could use in order to improve your system.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:17:11",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1031s",
      "context": "Describes a practical improvement flywheel: capture human decisions during oversight to generate data for continuous model/system iteration.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t7_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t7",
      "topic_title": "Behavior calibration, risk tiers, and flywheels",
      "text": "This idea of start slow with high control and low agency and then build up over time once you've built confidence that it's doing the right sort of work.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:17:41",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1061s",
      "context": "Summarizes a staged autonomy methodology practitioners can apply to reduce risk while scaling AI capabilities over time.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t8_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t8",
      "topic_title": "More autonomy ladder examples and why it matters",
      "text": "So say you're building a coding assistant, V1 would be just suggest inline completion and boilerplate snippets. V2 would be generate larger blocks like tests or refactors for humans to review. And then V3 is just apply the changes and open PRs autonomously.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:17:41",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1061s",
      "context": "A concrete \u201cautonomy ladder\u201d example practitioners can directly map onto their own product rollout from low to high agency.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t8_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t8",
      "topic_title": "More autonomy ladder examples and why it matters",
      "text": "I mean, if you think of it's also the most beautiful part of AI, which is, I mean, we are all much more comfortable talking than following a bunch of buttons and all of that. So the bar to using AI products is much lower because you can be as natural as you would be with humans, but that's also the problem, which is there are tons of ways we communicate and you want to make sure that that intent is rightly communicated and the right actions are taken because most of your systems are deterministic and you want to achieve a deterministic outcome, but with non-deterministic technology and that's where it gets a little messy.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:19:08",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1148s",
      "context": "Captures the core product tension: natural-language UX lowers adoption friction while increasing ambiguity and risk when interfacing with deterministic systems.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t8_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t8",
      "topic_title": "More autonomy ladder examples and why it matters",
      "text": "I feel there's a bunch of things that you actually have to get confidence in before you get to V3. And it's easy to get overwhelmed that, oh, my AI agent is doing these things wrong in a hundred different ways and you're not going to actually tabulate all of them and fix it.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:20:08",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1208s",
      "context": "Practical warning that jumping to full autonomy creates an unmanageable error surface area, making iteration and evaluation much harder.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t8_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t8",
      "topic_title": "More autonomy ladder examples and why it matters",
      "text": "So when you start small and when you start with building a very minimalistic version with high human control and low agency, it also forces you to think about what is the problem that I'm going to solve. We use this term called problem first.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:20:08",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1208s",
      "context": "Introduces a repeatable methodology\u2014start with constrained autonomy to enforce \u201cproblem first\u201d thinking instead of solution complexity.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t8_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t8",
      "topic_title": "More autonomy ladder examples and why it matters",
      "text": "one easy, slippery slope is to just keep thinking about complexities of the solution and forget the problem that you're trying to solve.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:20:08",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1208s",
      "context": "A memorable caution that AI teams often over-index on technical sophistication and lose sight of the user/job-to-be-done.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t9_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t9",
      "topic_title": "Reliability as top enterprise blocker",
      "text": "And there's so many other benefits to limiting autonomy because there's just danger also of the thing doing too much for you and just messing up your, I don't know, your database, sending out all these emails you never expected.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:21:31",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1291s",
      "context": "Highlights a practical risk-based rationale for constraining AI autonomy to prevent costly unintended actions in production systems.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t9_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t9",
      "topic_title": "Reliability as top enterprise blocker",
      "text": "it said about 74% or 75% of the enterprises that they had spoken to, their biggest problem was reliability.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:21:45",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1305s",
      "context": "Provides a concrete data point that reliability is the dominant blocker for enterprise AI adoption.",
      "insight_type": "data"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t9_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t9",
      "topic_title": "Reliability as top enterprise blocker",
      "text": "And that's also why they think a lot of AI products today have to do with productivity because it's much low autonomy versus end-to-end agents that would replace workflows.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:21:45",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1305s",
      "context": "Offers a useful mental model: productivity copilots succeed because they require lower autonomy than full workflow-replacing agents.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t9_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t9",
      "topic_title": "Reliability as top enterprise blocker",
      "text": "prompt injection and jailbreaking and just how big of a risk that is for AI products where it's essentially an unsolved and unsolvable problem potentially.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:22:38",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1358s",
      "context": "Frames security (prompt injection/jailbreaking) as a potentially unsolved constraint that should shape product scope and deployment decisions.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t10_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t10",
      "topic_title": "Prompt injection and guardrails risk discussion",
      "text": "I think that will be a huge problem once systems go mainstream.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:23:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1382s",
      "context": "Highlights a key risk-timing mental model: prompt injection becomes far more critical as AI systems reach mainstream adoption.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t10_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t10",
      "topic_title": "Prompt injection and guardrails risk discussion",
      "text": "We're still so busy building AI products that we're not worried about security, but it will be such a huge problem to kind of, especially with this non-deterministic API again.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:23:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1382s",
      "context": "Actionable warning that teams often underinvest in security early, and non-determinism makes traditional security assumptions harder.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t10_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t10",
      "topic_title": "Prompt injection and guardrails risk discussion",
      "text": "And there's all these guardrail systems people put in place, but turns out these guardrails aren't actually very good and you can always get around them.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:23:28",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1408s",
      "context": "Contrarian takeaway that \u201cguardrails\u201d alone are insufficient, implying practitioners need layered mitigations beyond prompt-level controls.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t10_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t10",
      "topic_title": "Prompt injection and guardrails risk discussion",
      "text": "So with the right sort of human in the loop points in here, I feel we can actually avoid a bunch of these things and focus more towards streamlining the processes.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:23:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1434s",
      "context": "Practical mitigation strategy: use human-in-the-loop checkpoints to reduce risk while still capturing near-term operational value.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t10_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t10",
      "topic_title": "Prompt injection and guardrails risk discussion",
      "text": "And I am more on the optimist side in the sense that you need to try and adopt this before actually trying to be only for highlighting the negative aspects of what could go wrong.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:23:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1434s",
      "context": "Counterbalances risk focus with an adoption-first mindset: iterate with safeguards rather than stalling due to worst-case scenarios.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t11_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t11",
      "topic_title": "Success triangle: leadership, culture, technical execution",
      "text": "I almost think of it as like a success triangle with three dimensions that's never always technical. Every technology problem is a people problem first. And with companies that we have worked with, it's these three dimensions, like great leaders, good culture and technical prowess.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:25:43",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1543s",
      "context": "Introduces a memorable \u201csuccess triangle\u201d framework that reframes AI product success as primarily people + leadership + culture, not just tech.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t11_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t11",
      "topic_title": "Success triangle: leadership, culture, technical execution",
      "text": "I used to work with the CEO of now Rackspace, Gagan. So he would have this block every day in the morning, which would say catching up with AI 4:00 to 6:00 AM, and he would not have any meetings or anything like that.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:26:42",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1602s",
      "context": "Concrete example of leaders creating dedicated time to rebuild intuition and stay hands-on with AI progress.",
      "insight_type": "story"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t11_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t11",
      "topic_title": "Success triangle: leadership, culture, technical execution",
      "text": "So I think leaders have to get back to being hands-on. And that's not because they have to be implementing these things, but more of rebuilding their intuitions because you must be comfortable with the fact that your intuitions might not be right and you probably are the dumbest person in the room and you want to learn from everyone.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:26:42",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1602s",
      "context": "Actionable leadership stance for AI transformation: hands-on learning and humility to update outdated intuition.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t11_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t11",
      "topic_title": "Success triangle: leadership, culture, technical execution",
      "text": "Whenever you're trying to automate some part of a workflow, it's never the case that you could use an AI agent and that will solve your problems. It's always, you probably have a machine learning model that's going to do some part of the job. You have deterministic code doing some part of the job.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:29:18",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1758s",
      "context": "Counter to \u201cagent solves everything\u201d thinking: successful systems are hybrid, combining ML/LLMs with deterministic software across a workflow.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t11_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t11",
      "topic_title": "Success triangle: leadership, culture, technical execution",
      "text": "To replace any critical workflow or to build something that can give you significant ROI, it easily takes four to six months of work, even if you have the best data layer and infrastructure layer.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:31:23",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=1883s",
      "context": "Sets realistic timelines for enterprise AI ROI, pushing back on \u201cinstant gains\u201d expectations.",
      "insight_type": "data"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t12_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t12",
      "topic_title": "Evals vs production monitoring: both are required",
      "text": "In terms of what is going on in the community, I feel there's just this false dichotomy of this either evals is going to solve everything or online monitoring or production monitoring is going to solve everything.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:33:47",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2027s",
      "context": "Reframes the debate as a false either/or and sets up a both/and operating model for reliability.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t12_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t12",
      "topic_title": "Evals vs production monitoring: both are required",
      "text": "Evals are basically your trusted product thinking or your knowledge about the product that is going into this set of data sets that you're going to build in the sense that this is what matters to me.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:33:47",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2027s",
      "context": "Defines evals as codified product intent\u2014turning what you care about into testable datasets.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t12_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t12",
      "topic_title": "Evals vs production monitoring: both are required",
      "text": "It's not just the customer always giving you explicit feedback, but there is many implicit feedback that you can get.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:34:47",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2087s",
      "context": "Actionable reminder to instrument implicit behavioral signals, not just explicit ratings, in production monitoring.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t12_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t12",
      "topic_title": "Evals vs production monitoring: both are required",
      "text": "Or if you don't like the answer, sometimes customers don't give you thumbs down, but actually regenerate the answer. So that is a clear indication that the initial answer that regenerator is not meeting the customer's expectation.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:34:47",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2087s",
      "context": "Concrete example of an implicit metric (regenerations) that can surface quality issues at scale.",
      "insight_type": "data"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t12_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t12",
      "topic_title": "Evals vs production monitoring: both are required",
      "text": "And once you get this kind of traces, you need to examine what are the failure patterns that you're seeing in these different types of interactions. And is there something that I really care about that should not happen? And if that kind of failure modes are happening, then I need to think about building an evaluation dataset for it.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:36:32",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2192s",
      "context": "Describes a practical loop: monitoring surfaces unknown failures, which then get converted into new eval datasets to prevent regressions.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t13_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t13",
      "topic_title": "Semantic diffusion: what people mean by \u201cevals\u201d",
      "text": "I think Martin Fowler at some point had this term called semantic diffusion back in the 2000s, which kind of means that someone comes up with a term, everybody starts butchering it with their own definitions and then you kind of lose the actual definition of it. That is what is happening to evals or agents or any word in AI as of today, everybody kind of sees a different side to it, I guess.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:39:02",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2342s",
      "context": "A useful mental model for why teams talk past each other about \u201cevals\u201d and how terminology drift creates process confusion.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t13_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t13",
      "topic_title": "Semantic diffusion: what people mean by \u201cevals\u201d",
      "text": "But if you make a bunch of practitioners sit together and ask them, \"Is it important to build an actionable feedback loop for AI products?\" I think all of them will agree. Now, how you do that really depends on your application itself.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:39:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2394s",
      "context": "Reframes \u201cevals\u201d as the broader goal of an actionable feedback loop, with implementation driven by product context.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t13_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t13",
      "topic_title": "Semantic diffusion: what people mean by \u201cevals\u201d",
      "text": "When you go to complex use cases, it's incredibly hard to build LLM judges because you see a lot of emerging patterns. If you built a judge that would test for verbosity or something like that, it turns out that you're seeing newer patterns that your LLM judge is not able to catch, and then you just end up building too many evals.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:39:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2394s",
      "context": "Warns that in complex domains, LLM-judge-based evals can fail to keep up with shifting failure modes and lead to eval sprawl.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t13_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t13",
      "topic_title": "Semantic diffusion: what people mean by \u201cevals\u201d",
      "text": "And at that point, it just makes sense to look at your user signals, fix them, check if you have regressed and move on instead of actually building these judges.",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:39:54",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2394s",
      "context": "Actionable guidance: prefer production/user signals and regression checks over over-investing in automated judges when patterns keep changing.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t13_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t13",
      "topic_title": "Semantic diffusion: what people mean by \u201cevals\u201d",
      "text": "I recently spoke to a client who told me, \"We do evals.\" And I was like, \"Okay, can you show me your dataset?\" And said, \"No, we just checked LM Arena and Artificial Analysis. These are independent benchmarks and we know that this model is the right one for our use case.\" And I'm like, \"You're not doing evals. That's not evals. Those are model evals.\"",
      "speaker": "Aishwarya Naresh Reganti",
      "timestamp": "00:41:03",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2463s",
      "context": "Concrete example of semantic diffusion: confusing external benchmarks with application-specific evaluation tied to your own data and use case.",
      "insight_type": "story"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t14_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t14",
      "topic_title": "How Kodex balances evals, vibes, and user feedback",
      "text": "So Kodex, we have this balanced approach of you need to have evals and you need to definitely listen to your customers.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:41:44",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2504s",
      "context": "A practical operating principle: pair formal evals with continuous customer listening rather than relying on either alone.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t14_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t14",
      "topic_title": "How Kodex balances evals, vibes, and user feedback",
      "text": "So it gets really hard to build an evaluation dataset for all kinds of interactions that your customers are going to use your product for.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:42:38",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2558s",
      "context": "Highlights a key limitation of evals for highly customizable products\u2014coverage is inherently incomplete\u2014pushing teams toward complementary feedback loops.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t14_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t14",
      "topic_title": "How Kodex balances evals, vibes, and user feedback",
      "text": "So those are the signals that you want to look at and make sure that your new changes are doing the right thing.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:43:36",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2616s",
      "context": "Emphasizes behavior-based signals (e.g., user reactions, switching off) as a core validation mechanism for model changes.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t14_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t14",
      "topic_title": "How Kodex balances evals, vibes, and user feedback",
      "text": "I don't think if anybody's coming and seeing that I have this concrete set of evals that I can bet my life on and then I don't need to think about anything else, it's not going to work.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:44:24",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2664s",
      "context": "A counterpoint to over-relying on evals: even strong eval suites can\u2019t replace ongoing human judgment and real-world monitoring.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t14_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t14",
      "topic_title": "How Kodex balances evals, vibes, and user feedback",
      "text": "And every new model that you're going to launch, we get together as a team and test different things. Each person is concentrating on something else. And we have this list of hard problems that we have and we throw that to the model and see how well they're progressing.",
      "speaker": "Kiriti Badam",
      "timestamp": "00:44:24",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2664s",
      "context": "Describes a repeatable team-based manual testing methodology using a shared \u201chard problems\u201d list to catch regressions and measure progress.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t15_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t15",
      "topic_title": "Sponsor Break",
      "text": "If you're a founder, the hardest part of starting a company isn't having the idea, it's scaling the business without getting buried in back office work.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:44:58",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2698s",
      "context": "Reframes the core founder challenge as operational scaling rather than ideation, guiding where to invest time and tooling.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t15_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t15",
      "topic_title": "Sponsor Break",
      "text": "With Brex, you get high limit corporate cards, easy banking, high yield treasury, plus a team of AI agents that handle manual finance tasks for you.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:44:58",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2698s",
      "context": "Concrete example of applying AI agents to automate routine finance operations, illustrating a practical AI product value proposition.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t15_q3",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t15",
      "topic_title": "Sponsor Break",
      "text": "They'll do all the stuff that you don't want to do, like file your expenses, scour transactions for waste, and run reports all according to your rules.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:44:58",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2698s",
      "context": "Actionable checklist of high-leverage finance workflows to automate with AI while keeping governance via rules.",
      "insight_type": "advice"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t15_q4",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t15",
      "topic_title": "Sponsor Break",
      "text": "One in three startups in the United States already runs on Brex.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:44:58",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2698s",
      "context": "Specific adoption data point that signals market traction and social proof for the platform.",
      "insight_type": "data"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t15_q5",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t15",
      "topic_title": "Sponsor Break",
      "text": "You call it the continuous calibration, continuous development framework.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:45:43",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2743s",
      "context": "Names a methodology for building AI products, hinting at an iterative, feedback-driven approach teams can adopt.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t16_q1",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t16",
      "topic_title": "Transition to continuous calibration framework",
      "text": "You call it the continuous calibration, continuous development framework.",
      "speaker": "Lenny",
      "timestamp": "00:45:43",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2743s",
      "context": "Names a concrete, repeatable methodology for building AI products that emphasizes ongoing calibration alongside development.",
      "insight_type": "framework"
    },
    {
      "quote_id": "aishwarya-naresh-reganti-kiriti-badam_t16_q2",
      "topic_id": "aishwarya-naresh-reganti-kiriti-badam_t16",
      "topic_title": "Transition to continuous calibration framework",
      "text": "Let's pull up a visual to show people what the heck we're talking about, and then just walk us through what this is, how this works, how teams can shift the way they build their AI products to this approach to help them avoid a lot of pain and suffering.",
      "speaker": "Lenny",
      "timestamp": "00:45:43",
      "youtube_link": "https://www.youtube.com/watch?v=z7T1pCxgvlA&t=2743s",
      "context": "Frames the framework as a practical team-level shift in process intended to prevent common AI product pitfalls.",
      "insight_type": "advice"
    }
  ]
}