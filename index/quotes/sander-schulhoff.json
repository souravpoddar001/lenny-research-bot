{
  "episode_id": "sander-schulhoff",
  "quotes": [
    {
      "quote_id": "sander-schulhoff_t1_q1",
      "topic_id": "sander-schulhoff_t1",
      "topic_title": "Introduction and Background",
      "text": "He created the very first prompt engineering guide on the internet, two months before ChatGPT was released.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:01:10",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=70s",
      "context": "Establishes Sander\u2019s credibility as an early practitioner, suggesting his techniques are grounded in long-running real-world iteration.",
      "insight_type": "story"
    },
    {
      "quote_id": "sander-schulhoff_t1_q2",
      "topic_id": "sander-schulhoff_t1",
      "topic_title": "Introduction and Background",
      "text": "He also partnered with OpenAI to run what was the first and is now the biggest AI red-teaming competition called HackAPrompt, and he now partners with frontier AI labs to produce research that makes their models more secure.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:01:10",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=70s",
      "context": "Highlights a practical methodology\u2014red teaming via competitions and lab partnerships\u2014as a path to improving model security.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t1_q3",
      "topic_id": "sander-schulhoff_t1",
      "topic_title": "Introduction and Background",
      "text": "Recently, he led the team behind The Prompt Report, which is the most comprehensive study of prompt engineering ever done.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:01:10",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=70s",
      "context": "Points to a consolidated evidence base practitioners can lean on rather than relying on anecdotal prompting tips.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t1_q4",
      "topic_id": "sander-schulhoff_t1",
      "topic_title": "Introduction and Background",
      "text": "It's 76 pages long, co-authored by OpenAI, Microsoft, Google, Princeton, Stanford, and other leading institutions, and they've analyzed over 1,500 papers and came up with 200 different prompting techniques.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:01:10",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=70s",
      "context": "Provides concrete scope and numbers that signal breadth of research and a large menu of techniques to test systematically.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t1_q5",
      "topic_id": "sander-schulhoff_t1",
      "topic_title": "Introduction and Background",
      "text": "In our conversation, we go through his five favorite prompting techniques, both basics and some advanced stuff. We also get into prompt injection and red teaming, which is so interesting and also just so important.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:01:57",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=117s",
      "context": "Frames a practical learning path: start with core techniques, then move to advanced methods and security-focused prompting.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t2_q1",
      "topic_id": "sander-schulhoff_t2",
      "topic_title": "Is prompt engineering still worth learning?",
      "text": "There's this old myth that we only use 3 to 5% of our brains. It might actually be true for how much we're getting out of AI, given our prompting skills.",
      "speaker": "Lenny Rachitsky",
      "timestamp": "00:05:46",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=346s",
      "context": "A memorable mental model that frames prompting skill as the limiting factor on how much value you extract from AI.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t2_q2",
      "topic_id": "sander-schulhoff_t2",
      "topic_title": "Is prompt engineering still worth learning?",
      "text": "And the ability to, it's called elicit certain performance improvements and behaviors from LLMs is a really big area of study.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:06:16",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=376s",
      "context": "Highlights that prompting is not just \u201ctips and tricks\u201d but a systematic way to reliably change model behavior and output quality.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t2_q3",
      "topic_id": "sander-schulhoff_t2",
      "topic_title": "Is prompt engineering still worth learning?",
      "text": "My perspective, and this has been validated over and over again, is that people will always be saying, \"It's dead,\" or \"It's going to be dead with the next model version,\" but then it comes out and it's not.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:06:16",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=376s",
      "context": "A counterintuitive observation that challenges the recurring belief that better models will eliminate the need for prompt engineering.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t2_q4",
      "topic_id": "sander-schulhoff_t2",
      "topic_title": "Is prompt engineering still worth learning?",
      "text": "And we actually came up with a term for this, which is artificial social intelligence.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:06:16",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=376s",
      "context": "Introduces a novel framework for thinking about prompting as a communication skill rather than a technical hack.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t2_q5",
      "topic_id": "sander-schulhoff_t2",
      "topic_title": "Is prompt engineering still worth learning?",
      "text": "We have recognized the need for a similar thing, but with communicating with AIs and understanding the best way to talk to them, understanding what their responses mean, and then how to adapt, I guess, your next prompts to that response.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:07:12",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=432s",
      "context": "Actionable methodology: treat prompting as an iterative loop\u2014interpret the AI\u2019s response and adapt the next prompt accordingly.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t3_q1",
      "topic_id": "sander-schulhoff_t3",
      "topic_title": "Real-world impact: medical coding prompt improvements",
      "text": "And so what I ended up doing was taking a long list of documents that I went and coded myself, or I guess got coded, and I took those and I attached reasonings as to why each one was coded in the way it was.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:07:48",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=468s",
      "context": "Shows a concrete, replicable method: curate labeled examples and add explicit reasoning to teach the model the decision process.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t3_q2",
      "topic_id": "sander-schulhoff_t3",
      "topic_title": "Real-world impact: medical coding prompt improvements",
      "text": "And then I took all of that data and dropped it into my prompt, and then went ahead and gave the model a new transcript it had never seen before.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:07:48",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=468s",
      "context": "Highlights an evaluation approach practitioners can copy: prompt with curated training-like examples, then test on an unseen input to measure generalization.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t3_q3",
      "topic_id": "sander-schulhoff_t3",
      "topic_title": "Real-world impact: medical coding prompt improvements",
      "text": "And that boosted the accuracy on that task up by, I think, 70%.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:07:48",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=468s",
      "context": "Provides a specific performance delta that underscores how much prompt quality can swing real-world outcomes.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t3_q4",
      "topic_id": "sander-schulhoff_t3",
      "topic_title": "Real-world impact: medical coding prompt improvements",
      "text": "So massive, massive performance improvements by having better prompts and doing prompt engineering well.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:07:48",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=468s",
      "context": "A memorable takeaway that reinforces the ROI of systematic prompt engineering rather than ad-hoc prompting.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t4_q1",
      "topic_id": "sander-schulhoff_t4",
      "topic_title": "Two modes: conversational vs product prompting",
      "text": "But the two modes are, first of all, there's the conversational mode in which most people do prompt engineering.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:09:26",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=566s",
      "context": "Introduces a clear two-mode framework that helps practitioners distinguish everyday chatbot iteration from production-grade prompting.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t4_q2",
      "topic_id": "sander-schulhoff_t4",
      "topic_title": "Two modes: conversational vs product prompting",
      "text": "Notably, that is not where the classical concept of prompt engineering came from.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:10:06",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=606s",
      "context": "Challenges the common assumption that prompt engineering is primarily about chatting better, reframing it as an engineering discipline.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t4_q3",
      "topic_id": "sander-schulhoff_t4",
      "topic_title": "Two modes: conversational vs product prompting",
      "text": "I have this product I'm building. I have this one prompt or a couple different prompts that are super critical to this product. I'm running thousands, millions of inputs through this prompt each day. I need this one prompt to be perfect.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:10:06",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=606s",
      "context": "Defines product-focused prompting with concrete scale and reliability requirements that change how you design and evaluate prompts.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t4_q4",
      "topic_id": "sander-schulhoff_t4",
      "topic_title": "Two modes: conversational vs product prompting",
      "text": "I just take this one prompt and improve it, and there's a lot of automated techniques out there to improve prompts, and keep improving it over and over again until it's something I've satisfied with, and then never change it.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:10:06",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=606s",
      "context": "Offers an actionable methodology: iterative optimization of a single production prompt (often via automation) followed by stability rather than constant tweaking.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t4_q5",
      "topic_id": "sander-schulhoff_t4",
      "topic_title": "Two modes: conversational vs product prompting",
      "text": "Yeah, absolutely, and most of the research is on those, I guess, now you've coined it as product-focused prompt engineering.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:11:51",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=711s",
      "context": "Signals where the field\u2019s evidence base is strongest\u2014useful for practitioners prioritizing techniques backed by research.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t5_q1",
      "topic_id": "sander-schulhoff_t5",
      "topic_title": "Basic technique: few-shot prompting and formatting",
      "text": "So my best advice on how to improve your prompting skills is actually just trial and error. You will learn the most from just trying and interacting with chatbots, and talking to them, than anything else, including reading resources, taking courses, all of that.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:12:18",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=738s",
      "context": "Emphasizes an experiential learning loop as the highest-leverage way to improve prompting, over passive learning.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t5_q2",
      "topic_id": "sander-schulhoff_t5",
      "topic_title": "Basic technique: few-shot prompting and formatting",
      "text": "But if there were one technique that I could recommend people, it is few-shot prompting, which is just giving the AI examples of what you want it to do.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:12:18",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=738s",
      "context": "Gives a simple, broadly applicable baseline technique that reliably boosts output quality.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t5_q3",
      "topic_id": "sander-schulhoff_t5",
      "topic_title": "Basic technique: few-shot prompting and formatting",
      "text": "But my main advice there is choose a common format.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:14:22",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=862s",
      "context": "Provides a practical heuristic for structuring few-shot prompts to improve model reliability.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t5_q4",
      "topic_id": "sander-schulhoff_t5",
      "topic_title": "Basic technique: few-shot prompting and formatting",
      "text": "But just take some common format out there that the LLM is comfortable with, and I say that with air quotes because it's a bit of a strange thing to say the LLM is comfortable with something, but it actually comes empirically from studies that have shown that formats of questions that show up most commonly in the training data are the best formats of questions to actually use when you're prompting it.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:14:22",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=862s",
      "context": "Connects prompt formatting to training-data frequency, offering an evidence-based rationale for why familiar schemas (Q/A, XML) work better.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t5_q5",
      "topic_id": "sander-schulhoff_t5",
      "topic_title": "Basic technique: few-shot prompting and formatting",
      "text": "You don't even necessarily have the inputs and the outputs. In your case, you just have, I guess, outputs that you're showing it from the past.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:17:20",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1040s",
      "context": "Highlights a simpler variant of few-shot prompting: showing only exemplar outputs can still steer generation effectively.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t6_q1",
      "topic_id": "sander-schulhoff_t6",
      "topic_title": "What no longer works: role prompting and threats",
      "text": "And so my thinking on this is that at some point with the GPT-3, early ChatGPT models, it might've been true that giving these roles provides a performance boost on accuracy-based tasks, but right now, it doesn't help at all. But giving a role really helps for expressive tasks, writing tasks, summarizing tasks. And so with those things where it's more about style, that's a great, great place to use roles. But my perspective is that roles do not help with any accuracy-based tasks whatsoever.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:20:36",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1236s",
      "context": "Clear, actionable guidance on when role prompting is useful (style) versus ineffective (accuracy), challenging a common best practice.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t6_q2",
      "topic_id": "sander-schulhoff_t6",
      "topic_title": "What no longer works: role prompting and threats",
      "text": "But if you looked at the actual results, data itself, the accuracies were 0.01 apart. So there's no statistical significance, and it's also really difficult to say which roles have better interpersonal ability.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:19:02",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1142s",
      "context": "A concrete data point showing role-prompting gains are negligible, encouraging practitioners to prioritize changes that actually move metrics.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t6_q3",
      "topic_id": "sander-schulhoff_t6",
      "topic_title": "What no longer works: role prompting and threats",
      "text": "So there's that. There's the one, oh, I'll tip you $5 if you do this, anything where you give some kind of promise of a reward or threat of some punishment in your prompt. And this was something that went quite viral, and there's a little bit of research on this. My general perspective is that these things don't work.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:22:32",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1352s",
      "context": "Directly debunks reward/threat prompting as an overhyped tactic practitioners should stop relying on.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t6_q4",
      "topic_id": "sander-schulhoff_t6",
      "topic_title": "What no longer works: role prompting and threats",
      "text": "During training, it's not told, \"Hey, do a good job on this and you'll get paid, and then...\" That's just not how training is done, and so that's why I don't think that's a great explanation.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:24:02",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1442s",
      "context": "A useful mental model for why \u201ctip/threat\u201d prompts shouldn\u2019t work: they don\u2019t match the model\u2019s training setup.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t7_q1",
      "topic_id": "sander-schulhoff_t7",
      "topic_title": "Basic technique: decomposition into subproblems",
      "text": "So decomposition is another really, really effective technique.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:25:03",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1503s",
      "context": "Names decomposition as a high-leverage prompting technique worth adding to a practitioner\u2019s toolkit.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t7_q2",
      "topic_id": "sander-schulhoff_t7",
      "topic_title": "Basic technique: decomposition into subproblems",
      "text": "So instead you give it this task and you say, \"Hey, don't answer this.\" Before answering it, tell me what are some subproblems that would need to be solved first?",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:25:03",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1503s",
      "context": "Provides a concrete, reusable prompt pattern for forcing stepwise planning before execution.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t7_q3",
      "topic_id": "sander-schulhoff_t7",
      "topic_title": "Basic technique: decomposition into subproblems",
      "text": "And honestly, this can help you think through the thing as well, which is half the power a lot of the time.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:25:03",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1503s",
      "context": "Highlights that decomposition improves not just model output but also the human\u2019s own problem clarity.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t7_q4",
      "topic_id": "sander-schulhoff_t7",
      "topic_title": "Basic technique: decomposition into subproblems",
      "text": "So a great example of this is a car dealership chat app.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:26:40",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1600s",
      "context": "Anchors the technique in a real product scenario where decomposition maps cleanly to workflow/tool calls.",
      "insight_type": "story"
    },
    {
      "quote_id": "sander-schulhoff_t7_q5",
      "topic_id": "sander-schulhoff_t7",
      "topic_title": "Basic technique: decomposition into subproblems",
      "text": "And so if you just ask the model to do all that at once, it might struggle. But if you tell it, \"Hey, what are all the things that need to be done first?\"",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:26:40",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1600s",
      "context": "Explains the practical performance benefit: breaking complex tasks into prerequisites reduces failure from one-shot prompting.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t8_q1",
      "topic_id": "sander-schulhoff_t8",
      "topic_title": "Basic technique: self-criticism and revision loops",
      "text": "Another one is a set of techniques that we call self-criticism. So, the idea here is you ask the LM to solve some problem. It does it, great, and then you're like, \"Hey, can you go and check your response, confirm that's correct, or offer yourself some criticism.\"",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:28:42",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1722s",
      "context": "Defines a repeatable prompting workflow: answer first, then explicitly trigger self-checking and critique.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t8_q2",
      "topic_id": "sander-schulhoff_t8",
      "topic_title": "Basic technique: self-criticism and revision loops",
      "text": "And then it gives you this list of criticism, and then you can say to it, \"Hey, great criticism, why don't you go ahead and implement that?\" And then it rewrites its solution.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:28:42",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1722s",
      "context": "Turns critique into concrete improvements by adding an explicit \u201cimplement the critique\u201d step.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t8_q3",
      "topic_id": "sander-schulhoff_t8",
      "topic_title": "Basic technique: self-criticism and revision loops",
      "text": "And so these are a pretty notable set of techniques, because it's like a free performance boost that works in some situations.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:28:42",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1722s",
      "context": "Memorable mental model: self-critique loops can yield quality gains without changing models or tools.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t8_q4",
      "topic_id": "sander-schulhoff_t8",
      "topic_title": "Basic technique: self-criticism and revision loops",
      "text": "Yeah, yeah. So, I don't know. I'll do it one just three times sometimes, but not really beyond that.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:29:46",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1786s",
      "context": "Practical guidance on iteration limits: 1\u20133 self-critique passes before diminishing returns.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t9_q1",
      "topic_id": "sander-schulhoff_t9",
      "topic_title": "Basic technique: add rich task information",
      "text": "You want to give it as much information about that task as possible.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:30:10",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1810s",
      "context": "A simple guiding principle for prompt design: maximize relevant task background to improve model performance.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t9_q2",
      "topic_id": "sander-schulhoff_t9",
      "topic_title": "Basic technique: add rich task information",
      "text": "So I took the email out and the performance dropped off a cliff without that context, without that additional information.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:33:19",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1999s",
      "context": "A concrete example showing how removing seemingly incidental context can cause dramatic quality regressions.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t9_q3",
      "topic_id": "sander-schulhoff_t9",
      "topic_title": "Basic technique: add rich task information",
      "text": "That is just one of the wacky oddities of prompting and prompt engineering, there's just small things you change to have massive unpredictable effects, but the lesson there is that including context or additional information about the situation was super, super important to get a performance prompt.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:33:19",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=1999s",
      "context": "A counterintuitive observation and takeaway: tiny prompt edits can swing results wildly, so rich task info is a key stabilizer.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t9_q4",
      "topic_id": "sander-schulhoff_t9",
      "topic_title": "Basic technique: add rich task information",
      "text": "I would say so. Yeah, that is pretty much my advice, especially in the conversational setting.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:34:16",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2056s",
      "context": "Direct, actionable guidance that in non-cost-constrained chat settings, you should generally include lots of additional information.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t9_q5",
      "topic_id": "sander-schulhoff_t9",
      "topic_title": "Basic technique: add rich task information",
      "text": "So subsequent calls to the LM with that same context at the top of the prompt are cheaper because the model provider stores that initial context for you as well as the embeddings for it.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:35:03",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2103s",
      "context": "A practical implementation tip: put reusable context at the top to benefit from caching and reduce cost/latency.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t10_q1",
      "topic_id": "sander-schulhoff_t10",
      "topic_title": "Prompt anatomy vs prompting techniques",
      "text": "And the way we define prompting techniques is special ways of architecting your prompt or special phrases that induce better performance.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:38:12",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2292s",
      "context": "Defines a practical boundary between basic prompt structure and true \u201ctechniques\u201d aimed at measurable performance gains.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t10_q2",
      "topic_id": "sander-schulhoff_t10",
      "topic_title": "Prompt anatomy vs prompting techniques",
      "text": "And so there are parts of a prompt which like the role, that's a part of a prompt. The examples are a part of a prompt. Giving good additional information is part of a prompt. The directive is a part of a prompt, and that's your core intent.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:38:53",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2333s",
      "context": "Provides a clear anatomy checklist practitioners can use to audit and improve prompts before reaching for advanced techniques.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t10_q3",
      "topic_id": "sander-schulhoff_t10",
      "topic_title": "Prompt anatomy vs prompting techniques",
      "text": "And then there's stuff like output formatting, and you might be like, I want a table or a bullet list of those questions. You're telling it how to structure its output. That's another component of a prompt, but not necessarily prompting technique in and of itself.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:38:53",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2333s",
      "context": "Counterintuitively reframes output formatting as prompt anatomy rather than a performance-boosting technique, helping teams avoid conflating clarity with capability gains.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t10_q4",
      "topic_id": "sander-schulhoff_t10",
      "topic_title": "Prompt anatomy vs prompting techniques",
      "text": "There's actually a lot of depth behind all this. There absolutely is.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:39:44",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2384s",
      "context": "Pushes back on the idea that prompt labels are mere semantics, implying the taxonomy matters for systematic practice and research.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t11_q1",
      "topic_id": "sander-schulhoff_t11",
      "topic_title": "Advanced technique: ensembling and reasoning experts",
      "text": "So ensembling techniques will take a problem and then you'll have multiple different prompts that go and solve the exact same problem.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:40:35",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2435s",
      "context": "Defines the core ensembling workflow practitioners can apply immediately: run multiple prompt variants on the same task.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t11_q2",
      "topic_id": "sander-schulhoff_t11",
      "topic_title": "Advanced technique: ensembling and reasoning experts",
      "text": "And I'll get back multiple different answers and then I'll take the answer that comes back most commonly.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:41:38",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2498s",
      "context": "Gives a concrete aggregation rule (majority vote) for turning multiple model outputs into a single higher-confidence answer.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t11_q3",
      "topic_id": "sander-schulhoff_t11",
      "topic_title": "Advanced technique: ensembling and reasoning experts",
      "text": "And the idea here is you have some question, it could be a math question, it could really be any question. And you get yourself together a set of experts. And these are basically different LLMs or LLMs prompted in different ways, or some of them might even have access to the internet or other databases.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:42:48",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2568s",
      "context": "Introduces the \u201cmixture of reasoning experts\u201d methodology: diversify solvers by model, prompting, and tool access.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t11_q4",
      "topic_id": "sander-schulhoff_t11",
      "topic_title": "Advanced technique: ensembling and reasoning experts",
      "text": "And one of the neat things about, well, roles as we discussed before which may or may not work, is that they can activate different regions of the model's neural brain and make it perform differently and better or worse on some tasks.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:43:32",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2612s",
      "context": "Counterintuitive rationale for role prompting: it can shift model behavior, so ensembling roles can improve outcomes even if any single role is unreliable.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t12_q1",
      "topic_id": "sander-schulhoff_t12",
      "topic_title": "Sponsor Break",
      "text": "So it could be the same exact model, it could be different models. There's lots of different ways of implementing this.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:44:22",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2662s",
      "context": "Highlights implementation flexibility\u2014practitioners can mix same or different models depending on constraints and goals.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t12_q2",
      "topic_id": "sander-schulhoff_t12",
      "topic_title": "Sponsor Break",
      "text": "Sure. So we started Vanta in 2018, focused on founders helping them start to build out their security programs and get credit for all of that hard security work with compliance certifications like SOC 2 or ISO 27001.",
      "speaker": "Christina Cacioppo",
      "timestamp": "00:44:49",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2689s",
      "context": "Frames compliance as a way to \u201cget credit\u201d for security work\u2014useful mental model for positioning security investments.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t12_q3",
      "topic_id": "sander-schulhoff_t12",
      "topic_title": "Sponsor Break",
      "text": "Today, we currently help over 9,000 companies including some startup household names like Atlassian, Ramp, and LangChain, start and scale their security programs and ultimately build trust by automating compliance, centralizing GRC, and accelerating security or reviews.",
      "speaker": "Christina Cacioppo",
      "timestamp": "00:44:49",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2689s",
      "context": "Provides concrete scale and a three-part methodology (automate compliance, centralize GRC, accelerate reviews) practitioners can map to their own programs.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t12_q4",
      "topic_id": "sander-schulhoff_t12",
      "topic_title": "Sponsor Break",
      "text": "But the idea is with automation, with AI, with software, we are helping customers build trust with prospects and customers in an efficient way.",
      "speaker": "Christina Cacioppo",
      "timestamp": "00:45:27",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2727s",
      "context": "Actionable takeaway: treat automation/AI as a trust-building lever, not just a cost-saving tool.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t12_q5",
      "topic_id": "sander-schulhoff_t12",
      "topic_title": "Sponsor Break",
      "text": "And our joke, we started this compliance company, so you don't have to.",
      "speaker": "Christina Cacioppo",
      "timestamp": "00:45:27",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2727s",
      "context": "Memorable positioning that captures the value proposition of outsourcing/automating compliance overhead.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t13_q1",
      "topic_id": "sander-schulhoff_t13",
      "topic_title": "Chain-of-thought prompting in the reasoning era",
      "text": "Generally not so useful anymore because as you just said, there's these reasoning models that have come out, and by default do that reasoning.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:46:13",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2773s",
      "context": "Clarifies when chain-of-thought prompting has diminishing returns: with modern reasoning models it\u2019s often redundant.",
      "insight_type": "framework"
    },
    {
      "quote_id": "sander-schulhoff_t13_q2",
      "topic_id": "sander-schulhoff_t13",
      "topic_title": "Chain-of-thought prompting in the reasoning era",
      "text": "And I was running, I guess, GPT-4 on a battery of thousands of inputs and I was finding 99 out of a hundred times it would write out its reasoning, great, and then give a final answer.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:46:13",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2773s",
      "context": "Provides a concrete, at-scale evaluation example showing that \u201cdefault reasoning\u201d behavior is high but not perfect.",
      "insight_type": "data"
    },
    {
      "quote_id": "sander-schulhoff_t13_q3",
      "topic_id": "sander-schulhoff_t13",
      "topic_title": "Chain-of-thought prompting in the reasoning era",
      "text": "But one in a hundred times it would just give a final answer, no reason.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:47:26",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2846s",
      "context": "Highlights a counterintuitive reliability gap that matters when you care about consistency across large test sets.",
      "insight_type": "contrarian"
    },
    {
      "quote_id": "sander-schulhoff_t13_q4",
      "topic_id": "sander-schulhoff_t13",
      "topic_title": "Chain-of-thought prompting in the reasoning era",
      "text": "But I had to add in that thought-inducing phrase like, make sure to write out all your reasoning in order to make sure that happens.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:47:26",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2846s",
      "context": "Actionable advice: explicit \u201cshow your reasoning\u201d instructions can stabilize outputs when models occasionally skip reasoning.",
      "insight_type": "advice"
    },
    {
      "quote_id": "sander-schulhoff_t13_q5",
      "topic_id": "sander-schulhoff_t13",
      "topic_title": "Chain-of-thought prompting in the reasoning era",
      "text": "But if you look at scale, if you're running millions of inputs through your prompt, oftentimes in order to make your prompt more robust, you'll still need to use those classical prompting techniques.",
      "speaker": "Sander Schulhoff",
      "timestamp": "00:47:26",
      "youtube_link": "https://www.youtube.com/watch?v=eKuFqQKYRrA&t=2846s",
      "context": "A practical mental model: prompting techniques that seem unnecessary in demos can still be required for robustness at production scale.",
      "insight_type": "framework"
    }
  ]
}